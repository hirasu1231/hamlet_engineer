(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{417:function(t,s,a){t.exports=a.p+"assets/img/zoom.9e568f4d.jpg"},461:function(t,s,a){t.exports=a.p+"assets/img/org_seg1.b4368dc3.png"},462:function(t,s,a){t.exports=a.p+"assets/img/org_seg2.34ccbcd0.png"},487:function(t,s,a){"use strict";a.r(s);var n=a(2),r=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h2",{attrs:{id:"python-espnetでオリジナルデータを学習しsemantic-segmentationを実施する-学習編"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#python-espnetでオリジナルデータを学習しsemantic-segmentationを実施する-学習編"}},[t._v("#")]),t._v(" Python, ESPNetでオリジナルデータを学習しSemantic Segmentationを実施する(学習編)")]),t._v(" "),n("p",[t._v("Semantic Segmentationの中で軽いモデルであるESPNetv2を実装します．"),n("br"),t._v("\n本稿ではCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施します．"),n("br"),t._v("\n今回はGoogle ColabとGoogle Driveを連携させて，notebook形式で実行してます．"),n("br")]),t._v(" "),n("blockquote",[n("p",[t._v("Google Colaboratory（以下Google Colab）は、Google社が無料で提供している機械学習の教育や研究用の開発環境です。開発環境はJupyter Notebookに似たインターフェースを持ち、Pythonの主要なライブラリがプリインストールされています。"),n("br"),t._v("\n引用元："),n("a",{attrs:{href:"https://interface.cqpub.co.jp/ail01/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Google Colabの使い方"),n("OutboundLink")],1)])]),t._v(" "),n("p",[t._v("最終的に，人以外の背景を着色して，zoomのバーチャル背景機能のようなクロマキー合成を実装したいです．"),n("br"),t._v(" "),n("img",{attrs:{src:a(417),alt:""}})]),t._v(" "),n("h2",{attrs:{id:"作業ディレクトリのファイル構成"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#作業ディレクトリのファイル構成"}},[t._v("#")]),t._v(" 作業ディレクトリのファイル構成")]),t._v(" "),n("p",[t._v("プロジェクトディレクトリはsegmentationとしています．度々，省略しています．")]),t._v(" "),n("div",{staticClass:"language-init extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("segmentation\n├── /EdgeNets\n│   ├── /vision_datasets\n│   │   ├── create_data.ipynb <- データ生成用ノートブック\n│   │   ├── /cityscapes\n│   │   └── /human_city  <- 仮オリジナルデータ\n│   │       ├── train.txt\n│   │       ├── val.txt\n│   │       ├── /train\n│   │       │   ├── /rgb\n│   │       │   └── /label\n│   │       └── /val\n│   │           ├── /rgb\n│   │           └── /label\n│   │\n│   ├── /results_segmentation <- モデルの出力ディレクトリ\n│   │   └── /human_city\n│   ├── /result_images <- 着色画像の出力ディレクトリ\n│   │   └── /human_city\n│   │\n│   ├── /sample_images <- サンプル画像\n│   ├── train_segmentation.py\n│   ├── test_segmentation.py\n│   ├── custom_test_segmentation.py <- 新規作成\n│   ├── custom_train_segmentation.py <- 新規作成\n│   └── (省略)\n└── ESPNetv2.ipynb <- 実行用ノートブック\n")])])]),n("h2",{attrs:{id:"オリジナルデータの学習"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#オリジナルデータの学習"}},[t._v("#")]),t._v(" オリジナルデータの学習")]),t._v(" "),n("h3",{attrs:{id:"オリジナルデータの学習コードの作成"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#オリジナルデータの学習コードの作成"}},[t._v("#")]),t._v(" オリジナルデータの学習コードの作成")]),t._v(" "),n("p",[t._v("デフォルトのtrain_segmentation.pyではオリジナルデータでの学習に対応していないため，オリジナルデータに対応した"),n("code",[t._v("custom_train_segmentation.py")]),t._v("を作成します．"),n("br"),t._v("\ntrain_segmentation.pyではそれぞれのデータセットのクラス数に自動で指定されるため，コマンドの引数で指定されるように変更します．"),n("br"),t._v("\nまた，miou_val, val_lossをエポックの度にtxtファイルに記述するようにしています．"),n("br")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# custom_train_segmentation.py")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ============================================")]),t._v("\n__author__ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sachin Mehta"')]),t._v("\n__license__ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MIT"')]),t._v("\n__maintainer__ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sachin Mehta"')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ============================================")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" argparse\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" os\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" nn\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" optim\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" utilities"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utils "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" save_checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model_parameters"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" compute_flops\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" utilities"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train_eval_seg "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" train_seg "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" train\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" utilities"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train_eval_seg "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" val_seg "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" val\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensorboard "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SummaryWriter\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" loss_fns"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("segmentation_loss "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SegmentationLoss\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" random\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" math\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" time\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" utilities"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print_utils "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    crop_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop_size\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("tuple")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Running Model at image resolution {}x{} with batch size {}'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isdir"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savedir"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makedirs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savedir"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'custom'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" data_loader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("segmentation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("custom_dataset_loader "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" CustomSegmentationDataset\n        train_dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CustomSegmentationDataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data_path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" train"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" crop_size"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" scale"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scale"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        val_dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CustomSegmentationDataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data_path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" train"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" crop_size"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" scale"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scale"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                         \n        seg_classes "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("num_classes\n        class_wts "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ones"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("seg_classes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        print_error_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Dataset: {} not yet supported'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        exit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Training samples: {}'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("train_dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Validation samples: {}'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("val_dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'espnetv2'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("segmentation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("espnetv2 "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" espnetv2_seg\n        args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("classes "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" seg_classes\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" espnetv2_seg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dicenet'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("segmentation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dicenet "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" dicenet_seg\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dicenet_seg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" classes"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("seg_classes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        print_error_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Arch: {} not yet supported'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        exit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("finetune"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isfile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("finetune"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Loading weights for finetuning from {}'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("finetune"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            weight_dict "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("finetune"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" map_location"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("device"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cpu'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_state_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("weight_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Done'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            print_warning_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'No file for finetuning. Please check.'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("freeze_bn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Freezing batch normalization layers'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" m "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("modules"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BatchNorm2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weight"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("requires_grad "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bias"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("requires_grad "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n    num_gpus "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("device_count"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    device "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cuda'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" num_gpus "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cpu'")]),t._v("\n\n    train_params "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'params'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_basenet_params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'params'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_segment_params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_mult"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    optimizer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" optim"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SGD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("train_params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" momentum"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("momentum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight_decay"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weight_decay"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    num_params "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model_parameters"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    flops "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" compute_flops"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'FLOPs for an input of size {}x{}: {:.2f} million'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" flops"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Network Parameters: {:.2f} million'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    writer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SummaryWriter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("log_dir"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savedir"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" comment"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Training and Validation logs'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        writer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_graph"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" input_to_model"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("except")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        print_log_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Not able to generate the graph. Likely because your model is not supported by ONNX"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    start_epoch "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n    best_miou "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isfile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"=> loading checkpoint '{}'\"")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            checkpoint "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" map_location"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("device"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cpu'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            start_epoch "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'epoch'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            best_miou "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'best_miou'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_state_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'state_dict'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            optimizer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_state_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'optimizer'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"=> loaded checkpoint '{}' (epoch {})\"")]),t._v("\n                               "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'epoch'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            print_warning_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"=> no checkpoint found at '{}'\"")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#criterion = nn.CrossEntropyLoss(weight=class_wts, reduction='none', ignore_index=args.ignore_idx)")]),t._v("\n    criterion "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SegmentationLoss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_classes"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("seg_classes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss_type"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loss_type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                         device"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("device"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ignore_idx"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ignore_idx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                         class_wts"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("class_wts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" num_gpus "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" num_gpus "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# for a single GPU, we do not need DataParallel wrapper for Criteria.")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# So, falling back to its internal wrapper")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallel "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" DataParallel\n            model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DataParallel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            criterion "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" utilities"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallel_wrapper "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" DataParallelModel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataParallelCriteria\n            model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DataParallelModel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            criterion "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DataParallelCriteria"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("criterion"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            criterion "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("backends"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cudnn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_available"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("backends"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cudnn "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" cudnn\n            cudnn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("benchmark "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n            cudnn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("deterministic "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n\n    train_loader "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataLoader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("train_dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" shuffle"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                           pin_memory"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_workers"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("workers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    val_loader "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataLoader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("val_dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" shuffle"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                         pin_memory"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_workers"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("workers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scheduler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fixed'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        step_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step_size\n        step_sizes "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("step_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ceil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("epochs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" step_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" utilities"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" FixedMultiStepLR\n        lr_scheduler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" FixedMultiStepLR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("base_lr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("step_sizes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" gamma"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_decay"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scheduler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'clr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        step_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step_size\n        step_sizes "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("step_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ceil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("epochs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" step_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" utilities"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" CyclicLR\n        lr_scheduler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CyclicLR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("min_lr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cycle_len"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("step_sizes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" gamma"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_decay"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scheduler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'poly'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" utilities"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" PolyLR\n        lr_scheduler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PolyLR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("base_lr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_epochs"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("epochs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" power"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("power"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scheduler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'hybrid'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" utilities"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" HybirdLR\n        lr_scheduler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" HybirdLR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("base_lr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_epochs"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("epochs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" clr_max"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("clr_max"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        cycle_len"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cycle_len"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scheduler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'linear'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" utilities"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LinearLR\n        lr_scheduler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LinearLR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("base_lr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_epochs"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("epochs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        print_error_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{} scheduler Not supported'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scheduler"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        exit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lr_scheduler"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savedir "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sep "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'arguments.json'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'w'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" outfile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" json\n        arg_dict "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("vars")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        arg_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'model_params'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{} '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        arg_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'flops'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{} '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flops"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("arg_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" outfile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    extra_info_ckpt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{}_{}_{}'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# val log txtfile")]),t._v("\n    txt_outpath "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savedir"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'val_logs.txt'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    txt_outfile "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("txt_outpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    txt_outfile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'epoch, miou_val, val_loss\\n'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" epoch "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start_epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("epochs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        lr_base "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_scheduler"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# set the optimizer with the learning rate")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# This can be done inside the MyLRScheduler")]),t._v("\n        lr_seg "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_base "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_mult\n        optimizer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("param_groups"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_base\n        optimizer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("param_groups"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_seg\n\n        print_info_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Running epoch {} with learning rates: base_net {:.6f}, segment_net {:.6f}'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_base"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_seg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        miou_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" train_loss "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" train_loader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" criterion"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seg_classes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" device"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("device"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        miou_val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val_loss "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val_loader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" criterion"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seg_classes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" device"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("device"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# write txtfile")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'epoch, miou_val, val_loss'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{},{:.2f}, {:.6f}'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" miou_val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val_loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        txt_outfile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{},{:.2f}, {:.6f}\\n'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" miou_val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val_loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# remember best miou and save checkpoint")]),t._v("\n        is_best "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" miou_val "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" best_miou\n        best_miou "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("miou_val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" best_miou"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        weights_dict "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("state_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" device "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cuda'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("state_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        save_checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'epoch'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" epoch "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'arch'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'state_dict'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" weights_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'best_miou'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" best_miou"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'optimizer'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" optimizer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("state_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" is_best"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savedir"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extra_info_ckpt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        writer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_scalar"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Segmentation/LR/base'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("round")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lr_base"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        writer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_scalar"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Segmentation/LR/seg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("round")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lr_seg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        writer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_scalar"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Segmentation/Loss/train'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" train_loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        writer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_scalar"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Segmentation/Loss/val'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val_loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        writer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_scalar"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Segmentation/mIOU/train'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" miou_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        writer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_scalar"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Segmentation/mIOU/val'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" miou_val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        writer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_scalar"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Segmentation/Complexity/Flops'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" best_miou"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ceil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flops"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        writer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_scalar"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Segmentation/Complexity/Params'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" best_miou"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ceil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    writer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    txt_outfile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" __name__ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"__main__"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" commons"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("general_details "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" segmentation_models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" segmentation_schedulers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" segmentation_loss_fns"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \\\n        segmentation_datasets\n\n    parser "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" argparse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ArgumentParser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--resume'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'path to checkpoint to resume from'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--workers'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'number of data loading workers'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--ignore-idx'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Index or label to be ignored during training'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# model details")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--freeze-bn'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" action"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'store_true'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Freeze BN params or not'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# dataset and result directories")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--dataset'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'pascal'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" choices"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'custom'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Datasets'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--data-path'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dataset path'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--coco-path'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'MS COCO dataset path'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--savedir'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./results_segmentation'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Location to save the results'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## only for cityscapes")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--coarse'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" action"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'store_true'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Want to use coarse annotations or not'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# scheduler details")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--scheduler'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'hybrid'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" choices"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("segmentation_schedulers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Learning rate scheduler (fixed, clr, poly)'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--epochs'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'num of training epochs'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--step-size'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("51")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'steps at which lr should be decreased'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--lr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9e")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'initial learning rate'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--lr-mult'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10.0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'initial learning rate'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--lr-decay'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'factor by which lr should be decreased'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--momentum'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'momentum'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--weight-decay'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4e")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'weight decay (default: 4e-5)'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# for Polynomial LR")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--power'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'power factor for Polynomial LR'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# for hybrid LR")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--clr-max'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("61")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Max number of epochs for cylic LR before '")]),t._v("\n                                  "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'changing last cycle to linear'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--cycle-len'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Duration of cycle'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# input details")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--batch-size'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("40")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'list of batch sizes'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--crop-size'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nargs"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'+'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'list of image crop sizes, with each item storing the crop size (should be a tuple).'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--loss-type'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ce'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" choices"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("segmentation_loss_fns"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Loss function (ce or miou)'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# model related params")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--s'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Factor by which channels will be scaled'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--model'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'espnet'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" choices"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("segmentation_models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Which model? basic= basic CNN model, res=resnet style)'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--channels'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Input channels'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--num-classes'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ImageNet classes. Required for loading the base network'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--finetune'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Finetune the segmentation model'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--model-width'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Model width'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--model-height'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("help")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Model height'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    args "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seed"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1882")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("manual_seed"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1882")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'custom'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("512")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scale "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.25")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1024")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scale "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.35")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2048")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scale "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            print_error_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Select image size from 512x256, 1024x512, 2048x1024'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        print_log_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Using scale = ({}, {})'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scale"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scale"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        print_error_message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{} dataset not yet supported'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("finetune"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weight_locations"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("classification "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" model_weight_map\n\n        weight_file_key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{}_{}'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" weight_file_key "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" model_weight_map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keys"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{} does not exist'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("weight_file_key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weights "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model_weight_map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("weight_file_key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weights "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isfile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("finetune"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{} weight file does not exist'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("finetune"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'crop-size argument must contain 2 values'")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data_path "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Dataset path is an empty string. Please check.'")]),t._v("\n\n    args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("tuple")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    timestr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strftime"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%Y%m%d-%H%M%S"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savedir "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{}/model_{}_{}/s_{}_sch_{}_loss_{}_res_{}_sc_{}_{}/{}'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savedir"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                               args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scheduler"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                               args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loss_type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scale"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scale"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" timestr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"オリジナルデータの学習-第1段階"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#オリジナルデータの学習-第1段階"}},[t._v("#")]),t._v(" オリジナルデータの学習(第1段階)")]),t._v(" "),n("p",[t._v("最初の段階では、低解像度の画像を入力として使用して、より大きなバッチサイズに合わせることができます。"),n("br"),t._v("\nモデルは，"),n("code",[t._v("./results_segmentation/human_city")]),t._v("に出力されます．"),n("br"),t._v(" "),n("code",[t._v("--num-classes")]),t._v("でクラス数を指定することを忘れずに．")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("segmentation"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("EdgeNets\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# original dataset")]),t._v("\n!CUDA_VISIBLE_DEVICES"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" python custom_train_segmentation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("model espnetv2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("s "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("dataset custom \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("savedir "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("results_segmentation"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("human_city \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("path "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("vision_datasets"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("human_city"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("batch"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("size "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("crop"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("size "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("512")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("num"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("classes "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("lr "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.009")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("scheduler hybrid "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("clr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("61")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("epochs "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("\n")])])]),n("h3",{attrs:{id:"オリジナルデータの学習-第2段階"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#オリジナルデータの学習-第2段階"}},[t._v("#")]),t._v(" オリジナルデータの学習(第2段階)")]),t._v(" "),n("p",[t._v("第2段階では、バッチ正規化レイヤーをフリーズしてから、わずかに高い画像解像度で微調整します。"),n("br"),t._v("\n--finetuneでは，第1段階で出力した学習モデルを指定します．"),n("br"),t._v("\nここでも，"),n("code",[t._v("--num-classes")]),t._v("でクラス数を指定することを忘れずに．")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# original dataset")]),t._v("\n!CUDA_VISIBLE_DEVICES"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" python custom_train_segmentation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("model espnetv2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("s "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("dataset custom \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("savedir "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("results_segmentation"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("human_city0318 \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("path "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("vision_datasets"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("human_city"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("batch"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("size "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("crop"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("size "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1024")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("512")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("lr "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.005")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("scheduler hybrid "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("clr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("61")]),t._v("\\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("epochs "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("freeze"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("bn \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("num"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("classes "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("finetune "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("results_segmentation"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("human_city"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("model_espnetv2_custom"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("s_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("0_sch_hybrid_loss_ce_res_512_sc_0"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("25_0"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("＊＊＊＊"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("espnetv2_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("0_512_best"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pth\n\n")])])]),n("h2",{attrs:{id:"オリジナルデータモデルのテスト"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#オリジナルデータモデルのテスト"}},[t._v("#")]),t._v(" オリジナルデータモデルのテスト")]),t._v(" "),n("h3",{attrs:{id:"テストの実行"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#テストの実行"}},[t._v("#")]),t._v(" テストの実行")]),t._v(" "),n("p",[t._v("オリジナルデータで学習したモデルで/sample_dataの画像でsegmentationを実施しました．"),n("br"),t._v("\n以下のコマンドで実行できます．")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("segmentation"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("EdgeNets\n!CUDA_VISIBLE_DEVICES"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" python custom_test_segmentation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("model espnetv2 \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("s "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("dataset custom \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("path "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("sample_images"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("split custom \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("im"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("size "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1024")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("512")]),t._v("\\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("num"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("classes "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("weights"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("test "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("results_segmentation"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("human_city0318"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("model_espnetv2_custom"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("s_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("0_sch_hybrid_loss_ce_res_1024_sc_0"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("35_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("＊＊＊＊"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("espnetv2_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("0_1024_best"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pth \\\n                        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("savedir"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("name sample_images_org\n")])])]),n("h3",{attrs:{id:"テスト結果"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#テスト結果"}},[t._v("#")]),t._v(" テスト結果")]),t._v(" "),n("p",[t._v("Cityscapesデータセットの人は立っている状態ばかりなので，立っている人は着色されていますが，座っている人は着色されませんでした．"),n("br"),t._v("\n学習データに入っていないので当然ですが，このようにはっきり形となって出ると，面白いです．"),n("br"),t._v(" "),n("br"),t._v("\n立っている人の画像"),n("br"),t._v(" "),n("img",{attrs:{src:a(461),alt:""}}),n("br"),t._v(" "),n("br"),t._v("\n座っている人の画像"),n("br"),t._v(" "),n("img",{attrs:{src:a(462),alt:""}})]),t._v(" "),n("h2",{attrs:{id:"まとめ"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#まとめ"}},[t._v("#")]),t._v(" まとめ")]),t._v(" "),n("p",[t._v("本稿ではCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施しました．"),n("br"),t._v("\n次回から，セグメンテーションしてクロマキー合成を実施したいです．")]),t._v(" "),n("h2",{attrs:{id:"参考サイト"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#参考サイト"}},[t._v("#")]),t._v(" 参考サイト")]),t._v(" "),n("p",[n("a",{attrs:{href:"https://github.com/sacmehta/EdgeNets",target:"_blank",rel:"noopener noreferrer"}},[t._v("sacmehta/EdgeNets"),n("OutboundLink")],1),n("br"),t._v(" "),n("a",{attrs:{href:"https://github.com/sacmehta/EdgeNets/blob/master/README_Segmentation.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("sacmehta/EdgeNets/README_Segmentation.md"),n("OutboundLink")],1),t._v(" "),n("a",{attrs:{href:"https://qiita.com/tokyokuma/items/37b1370ea7c84399fbb9",target:"_blank",rel:"noopener noreferrer"}},[t._v("ESPNetで自作データセットを学習してセグメンテーション"),n("OutboundLink")],1),n("br"),t._v(" "),n("a",{attrs:{href:"https://rikoubou.hatenablog.com/entry/2019/02/21/190310",target:"_blank",rel:"noopener noreferrer"}},[t._v("【python/OpenCV】画像の特定の色を抽出する方法"),n("OutboundLink")],1),n("br"),t._v(" "),n("a",{attrs:{href:"https://qiita.com/pashango2/items/d6dda5f07109ee5b6163",target:"_blank",rel:"noopener noreferrer"}},[t._v("PIL/Pillowで画像の色を高速に置換する"),n("OutboundLink")],1),n("br"),t._v(" "),n("a",{attrs:{href:"http://ni4muraano.hatenablog.com/entry/2017/05/15/000000",target:"_blank",rel:"noopener noreferrer"}},[t._v("【OpenCV】 forループを使わずに指定した色を別の色に変更する"),n("OutboundLink")],1)])])}),[],!1,null,null,null);s.default=r.exports}}]);